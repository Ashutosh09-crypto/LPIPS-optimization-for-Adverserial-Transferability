{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 51\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "\n",
    "model = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.save(model.state_dict(), 'models/resnet18.pth')\n",
    "model = models.resnet18()\n",
    "model.load_state_dict(torch.load('models/resnet18.pth'))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# load the ImageNet class labels\n",
    "labels_url = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "labels = requests.get(labels_url).json()\n",
    "\n",
    "def preprocess_image(image):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    preprocessed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "    return preprocessed_image  # Add batch dimension\n",
    "\n",
    "\n",
    "def classify_image(image_tensor):\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    # Get the predicted class\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Print the predicted class label\n",
    "    print(\"Predicted class:\", predicted.item())\n",
    "\n",
    "\n",
    "image_path = \"LPIPS_Images/Lpips_image_1.jpg\" \n",
    "image = Image.open(image_path)\n",
    "image_tensor = preprocess_image(image)\n",
    "\n",
    "classify_image(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction loss: 0.19428707659244537  for  LPIPS_Images\\Lpips_image_0.jpg\n",
      "Prediction loss: 0.19406099617481232  for  LPIPS_Images\\Lpips_image_1.jpg\n",
      "Prediction loss: 0.36393511295318604  for  LPIPS_Images\\Lpips_image_2.jpg\n",
      "Prediction loss: 0.5075499415397644  for  LPIPS_Images\\Lpips_image_3.jpg\n",
      "Prediction loss: 2.0331428050994873  for  LPIPS_Images\\Lpips_image_4.jpg\n",
      "Prediction loss: 3.7291922569274902  for  LPIPS_Images\\Lpips_image_5.jpg\n",
      "Prediction loss: 4.2316365242004395  for  LPIPS_Images\\Lpips_image_6.jpg\n",
      "Prediction loss: 5.045066833496094  for  LPIPS_Images\\Lpips_image_7.jpg\n",
      "Prediction loss: 5.67869234085083  for  LPIPS_Images\\Lpips_image_8.jpg\n",
      "Prediction loss: 5.892947673797607  for  LPIPS_Images\\Lpips_image_9.jpg\n",
      "Prediction loss: 11.069872856140137  for  LPIPS_Images\\sit.jpg\n"
     ]
    }
   ],
   "source": [
    "# making ground label\n",
    "def ground_truth(true_class):\n",
    "    truth_tensor = [0]*1000\n",
    "    class_index = labels.index(true_class)\n",
    "    # print(\"class index of \"+ true_class, class_index)\n",
    "    truth_tensor[class_index] = 1\n",
    "    truth_tensor = torch.tensor(truth_tensor).unsqueeze(0).to(device)\n",
    "    truth_tensor = truth_tensor.to(torch.float32)\n",
    "\n",
    "    return truth_tensor\n",
    "\n",
    "directory = \"LPIPS_Images\"\n",
    "images_path = os.listdir(directory)\n",
    "\n",
    "for file in images_path:\n",
    "    file = os.path.join(directory, file)\n",
    "    image = Image.open(file)\n",
    "    image_tensor = preprocess_image(image)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "    # compute the loss\n",
    "    ground_truth_tensor = ground_truth('triceratops')\n",
    "    loss = F.cross_entropy(outputs,ground_truth_tensor)\n",
    "    print(\"Prediction loss:\", loss.item(), \" for \", file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
